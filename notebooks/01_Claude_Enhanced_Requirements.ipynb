{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Requirements Analysis with Claude Enhancement\n",
    "**Analyzes requirement similarities using sentence transformers and enhances results with Claude AI for improved requirement association detection.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [0] - Setup and Imports\n",
    "# Purpose: Import all required libraries and configure environment settings for Multi-LLM testing\n",
    "# Dependencies: os, sys, pathlib, dotenv, datetime, praxis_sentence_transformer\n",
    "# Breadcrumbs: Setup -> Imports -> Environment Configuration\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Import from praxis_sentence_transformer package (installed via pip)\n",
    "from praxis_sentence_transformer.neo4j_operations import Neo4jClient\n",
    "from praxis_sentence_transformer.analysis.analyzer import RequirementsAnalyzer\n",
    "from praxis_sentence_transformer.clients.claude import ClaudeRequirementAnalyzer, RequirementMatch, AnalysisResult\n",
    "from praxis_sentence_transformer.logger import setup_logging, DebugTimer\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging(\"neo4j-notebook\", logging.DEBUG)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [1] - Neo4j Connection Setup\n",
    "# Purpose: Initialize Neo4j client and establish database connection for requirements analysis\n",
    "# Dependencies: Neo4jClient, logger, sys\n",
    "# Breadcrumbs: Setup -> Database Connection -> Neo4j Client Initialization\n",
    "\n",
    "client = Neo4jClient()\n",
    "\n",
    "# Test connection\n",
    "if not client.connect():\n",
    "    logger.error(\"Failed to connect to Neo4j database\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [2] - Configuration and Analyzer Setup\n",
    "# Purpose: Configure model parameters and initialize requirements analyzer for processing\n",
    "# Dependencies: Path, logger, RequirementsAnalyzer\n",
    "# Breadcrumbs: Setup -> Configuration -> Analyzer Initialization\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "alpha = 0.6\n",
    "threshold = 0.4\n",
    "\n",
    "# Create results directory\n",
    "results_dir = Path(\"results/neo4j_analysis\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Using model: {model_name}\")\n",
    "logger.info(f\"Alpha: {alpha}\")\n",
    "logger.info(f\"Threshold: {threshold}\")\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = RequirementsAnalyzer(\n",
    "    neo4j_client=client,\n",
    "    model_name=model_name,\n",
    "    alpha=alpha,\n",
    "    threshold=threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [3] - Run Requirements Analysis\n",
    "# Purpose: Execute the main requirements analysis process and collect statistics\n",
    "# Dependencies: DebugTimer, analyzer\n",
    "# Breadcrumbs: Setup -> Analysis Execution -> Requirements Processing\n",
    "\n",
    "with DebugTimer(\"Running requirements analysis\"):\n",
    "    stats = analyzer.analyze_requirements(results_dir)\n",
    "\n",
    "print(\"\\nAnalysis Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [4] - Example Analysis Display\n",
    "# Purpose: Display detailed analysis results for first requirement match as example\n",
    "# Dependencies: analyzer, stats\n",
    "# Breadcrumbs: Analysis Execution -> Results Display -> Example Match Visualization\n",
    "\n",
    "# Show detailed analysis for first requirement with matches\n",
    "matches = stats.get(\"requirements_with_matches\", 0)\n",
    "if matches > 0:\n",
    "    print(\"\\nDetailed Analysis Example:\")\n",
    "    example_data = analyzer.get_example_match()\n",
    "    if example_data:\n",
    "        print(f\"\\nSource Requirement ID: {example_data['source']['id']}\")\n",
    "        print(f\"Source Content: {example_data['source']['content']}\")\n",
    "        print(f\"\\nMatching Requirements ({len(example_data['targets'])}):\")\n",
    "        for i, target in enumerate(example_data['targets'], 1):\n",
    "            print(f\"\\nMatch {i}:\")\n",
    "            print(f\"Target ID: {target['id']}\")\n",
    "            print(f\"Similarity Score: {target['similarity']:.3f}\")\n",
    "            print(f\"Content: {target['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [5] - Claude Analyzer Initialization\n",
    "# Purpose: Initialize Claude AI analyzer for enhanced requirement association analysis\n",
    "# Dependencies: ClaudeRequirementAnalyzer, RequirementMatch, AnalysisResult, logging, os\n",
    "# Breadcrumbs: Analysis Execution -> AI Enhancement -> Claude Integration Setup\n",
    "\n",
    "# Enable debug logging\n",
    "logging.getLogger('praxis_sentence_transformer.clients.claude.requirements_analyzer').setLevel(logging.DEBUG)\n",
    "\n",
    "logger.info(\"Initializing Claude analyzer...\")\n",
    "\n",
    "# Initialize analyzer with settings from environment variables\n",
    "claude_analyzer = ClaudeRequirementAnalyzer(\n",
    "    model=os.getenv('CLAUDE_3_5_MODEL', 'claude-3-sonnet-20240229'),\n",
    "    min_association_probability=float(os.getenv('MIN_COVERAGE_THRESHOLD', '0.6'))\n",
    ")\n",
    "\n",
    "# Use example_data directly since we already have it\n",
    "requirement_matches = []\n",
    "if example_data:\n",
    "    source_id = example_data['source']['id']\n",
    "    source_content = example_data['source']['content']\n",
    "    \n",
    "    for target in example_data['targets']:\n",
    "        target_id = target['id']\n",
    "        target_content = target['content']\n",
    "        similarity = target['similarity']\n",
    "        \n",
    "        # Only analyze pairs above similarity threshold\n",
    "        if similarity >= threshold:\n",
    "            # Create RequirementMatch object using the dataclass constructor\n",
    "            match = RequirementMatch(\n",
    "                source_id=source_id,\n",
    "                source_content=source_content,\n",
    "                target_id=target_id,\n",
    "                target_content=target_content,\n",
    "                similarity_score=similarity,\n",
    "                association_probability=0.0,  # Will be set by Claude\n",
    "                is_associated=False,  # Will be set by Claude\n",
    "                explanation=\"\",  # Will be set by Claude\n",
    "                timestamp=datetime.now()\n",
    "            )\n",
    "            requirement_matches.append(match)\n",
    "\n",
    "logger.info(f\"Created {len(requirement_matches)} requirement matches for analysis\")\n",
    "\n",
    "# Analyze requirements using Claude\n",
    "with DebugTimer(\"Running Claude analysis\"):\n",
    "    results = claude_analyzer.analyze_requirement_matches(requirement_matches)\n",
    "\n",
    "# Save results\n",
    "output_dir = results_dir / \"claude_analysis\"\n",
    "claude_analyzer.save_results(results, output_dir)\n",
    "\n",
    "# Print summary\n",
    "associated_matches = [r for r in results if r.is_associated]\n",
    "print(f\"\\nClaude Analysis Summary:\")\n",
    "print(f\"Total matches analyzed: {len(requirement_matches)}\")\n",
    "print(f\"Associated matches found: {len(associated_matches)}\")\n",
    "if results:\n",
    "    avg_prob = sum(r.association_probability for r in results)/len(results)\n",
    "    print(f\"Average association probability: {avg_prob:.3f}\")\n",
    "print(f\"\\nResults saved to: {output_dir}\")\n",
    "\n",
    "# Display example matches\n",
    "if associated_matches:\n",
    "    print(\"\\nExample Associated Requirements:\")\n",
    "    for match in associated_matches[:5]:  # Show first 5 matches\n",
    "        print(f\"\\nSource {match.source_id} -> Target {match.target_id}\")\n",
    "        print(f\"Association Probability: {match.association_probability:.3f}\")\n",
    "        print(f\"Explanation: {match.explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [6] - Batch Requirements Processing with Claude\n",
    "# Purpose: Process all requirement matches from Neo4j using Claude for comprehensive analysis\n",
    "# Dependencies: ClaudeRequirementAnalyzer, RequirementMatch, datetime, client, logger\n",
    "# Breadcrumbs: AI Enhancement -> Batch Processing -> Claude Analysis Pipeline\n",
    "\n",
    "# Initialize Claude analyzer\n",
    "claude_analyzer = ClaudeRequirementAnalyzer()\n",
    "\n",
    "# Get model configuration from environment\n",
    "model_name = eval(os.getenv('MODEL_LIST', '[\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"]'))[0]\n",
    "alpha = float(eval(os.getenv('ALPHA_VALUES', '[0.6]'))[0])\n",
    "threshold = float(eval(os.getenv('THRESHOLD_RANGE', '[0.4]'))[0])\n",
    "\n",
    "# Get requirement matches from Neo4j using existing client\n",
    "raw_matches = client.get_requirement_matches(\n",
    "    model_name=model_name,\n",
    "    alpha=alpha,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "logger.info(f\"Retrieved {len(raw_matches)} raw matches from Neo4j\")\n",
    "\n",
    "# Debug the structure of raw matches\n",
    "if raw_matches:\n",
    "    logger.debug(f\"Sample raw match structure: {raw_matches[0]}\")\n",
    "\n",
    "# Convert dictionary matches to RequirementMatch objects\n",
    "requirement_matches = []\n",
    "for match in raw_matches:\n",
    "    try:\n",
    "        # Extract source and target info from match structure\n",
    "        source = match.get('source', {})\n",
    "        target = match.get('target', {})\n",
    "        \n",
    "        if not source or not target:\n",
    "            logger.warning(f\"Skipping match due to missing source or target: {match}\")\n",
    "            continue\n",
    "            \n",
    "        # Create RequirementMatch object using the dataclass constructor\n",
    "        req_match = RequirementMatch(\n",
    "            source_id=source.get('id'),\n",
    "            source_content=source.get('content'),\n",
    "            target_id=target.get('id'),\n",
    "            target_content=target.get('content'),\n",
    "            similarity_score=match.get('similarity', 0.0),\n",
    "            association_probability=0.0,  # Will be set by Claude\n",
    "            is_associated=False,  # Will be set by Claude\n",
    "            explanation=\"\",  # Will be set by Claude\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        requirement_matches.append(req_match)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing match: {str(e)}\")\n",
    "        logger.debug(f\"Problematic match structure: {match}\")\n",
    "        continue\n",
    "\n",
    "logger.info(f\"Converted {len(requirement_matches)} matches to RequirementMatch objects\")\n",
    "\n",
    "# Analyze matches with Claude\n",
    "analyzed_matches = claude_analyzer.analyze_requirement_matches(requirement_matches)\n",
    "\n",
    "# Save results\n",
    "output_dir = results_dir / \"claude_analysis\"\n",
    "claude_analyzer.save_results(analyzed_matches, output_dir)\n",
    "\n",
    "# Print summary statistics\n",
    "associated_matches = [m for m in analyzed_matches if m.is_associated]\n",
    "print(f\"\\nAnalysis Summary:\")\n",
    "print(f\"Total matches analyzed: {len(analyzed_matches)}\")\n",
    "print(f\"Associated matches found: {len(associated_matches)}\")\n",
    "if analyzed_matches:\n",
    "    avg_prob = sum(m.association_probability for m in analyzed_matches)/len(analyzed_matches)\n",
    "    print(f\"Average association probability: {avg_prob:.3f}\")\n",
    "\n",
    "# Display example matches\n",
    "if associated_matches:\n",
    "    print(\"\\nExample Associated Requirements:\")\n",
    "    for match in associated_matches[:5]:  # Show first 5 matches\n",
    "        print(f\"\\nSource {match.source_id} -> Target {match.target_id}\")\n",
    "        print(f\"Association Probability: {match.association_probability:.3f}\")\n",
    "        print(f\"Explanation: {match.explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [7] - Cleanup and Session Termination\n",
    "# Purpose: Close database connections and finalize analysis session\n",
    "# Dependencies: client, logger\n",
    "# Breadcrumbs: Analysis Pipeline -> Session Management -> Resource Cleanup\n",
    "\n",
    "client.close()\n",
    "logger.info(\"Analysis complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
