{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# HuggingFace Model API Testing\n",
    "**Tests HuggingFace Zephyr model capabilities through API endpoints with simple and complex prompt scenarios for text generation evaluation.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [0] - Library Import and Environment Configuration\n",
    "# Purpose: Import HuggingFace libraries and load environment variables for model access\n",
    "# Dependencies: os, dotenv, langchain_huggingface, langchain.callbacks\n",
    "# Breadcrumbs: Setup -> Library Import -> HuggingFace Integration\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [1] - Zephyr Model Initialization\n",
    "# Purpose: Initialize HuggingFace Zephyr model with specific parameters for text generation testing\n",
    "# Dependencies: HuggingFaceEndpoint, StreamingStdOutCallbackHandler, os\n",
    "# Breadcrumbs: HuggingFace Integration -> Model Initialization -> Parameter Configuration\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=os.getenv(\"HF_TOKEN\"),\n",
    "    max_new_tokens=512,\n",
    "    top_k=30,\n",
    "    top_p=0.9,\n",
    "    temperature=0.7,\n",
    "    repetition_penalty=1.03,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [2] - Simple Model Testing\n",
    "# Purpose: Test the initialized model with a basic prompt to verify functionality and response quality\n",
    "# Dependencies: llm\n",
    "# Breadcrumbs: Model Initialization -> Basic Testing -> Response Validation\n",
    "\n",
    "prompt = \"\"\"<|system|>\n",
    "You are a helpful AI assistant.\n",
    "<|user|>\n",
    "What are three interesting facts about space exploration?\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(\"\\nFull response:\", response)  # Print the full response after streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [3] - Complex Model Testing\n",
    "# Purpose: Test the model with a more complex programming prompt to evaluate advanced reasoning capabilities\n",
    "# Dependencies: llm\n",
    "# Breadcrumbs: Basic Testing -> Advanced Testing -> Complex Task Evaluation\n",
    "\n",
    "prompt = \"\"\"<|system|>\n",
    "You are a Python programming expert who helps write clean, efficient code.\n",
    "<|user|>\n",
    "Write a function that calculates the Fibonacci sequence up to n terms using dynamic programming.\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(\"\\nFull response:\", response)  # Print the full response after streaming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
